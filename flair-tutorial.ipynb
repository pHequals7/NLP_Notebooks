{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\r\n",
      "\u001b[K     |████████████████████████████████| 143kB 2.7MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pytest>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from flair) (4.6.2)\r\n",
      "Requirement already satisfied: mpld3==0.3 in /opt/conda/lib/python3.6/site-packages (from flair) (0.3)\r\n",
      "Collecting sqlitedict>=1.6.0 (from flair)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\r\n",
      "Collecting deprecated>=1.2.4 (from flair)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\r\n",
      "Collecting segtok>=1.5.7 (from flair)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\r\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.6/site-packages (from flair) (3.1.0)\r\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /opt/conda/lib/python3.6/site-packages (from flair) (0.1.2)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from flair) (2019.6.8)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from flair) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.6/site-packages (from flair) (4.32.1)\r\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (from flair) (0.0)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /opt/conda/lib/python3.6/site-packages (from flair) (1.24.2)\r\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from flair) (0.6.2)\r\n",
      "Requirement already satisfied: gensim>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from flair) (3.7.3)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from flair) (0.8.3)\r\n",
      "Collecting bpemb>=0.2.9 (from flair)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (1.8.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (1.12.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (19.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (19.1.0)\r\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (1.3.0)\r\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.12.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.17)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (0.1.7)\r\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest>=3.6.4->flair) (7.0.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1 in /opt/conda/lib/python3.6/site-packages (from deprecated>=1.2.4->flair) (1.11.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.8.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.16.4)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\r\n",
      "Requirement already satisfied: networkx==2.2 in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (2.2)\r\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (3.8.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from hyperopt>=0.1.1->flair) (1.3.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn->flair) (0.21.2)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.173)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.22.0)\r\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim>=3.4.0->flair) (1.8.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from bpemb>=0.2.9->flair) (0.1.82)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest>=3.6.4->flair) (0.5.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (41.0.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx==2.2->hyperopt>=0.1.1->flair) (4.4.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn->flair) (0.13.2)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.173 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.173)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.6.16)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\r\n",
      "Requirement already satisfied: boto>=2.32 in /opt/conda/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.173->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\r\n",
      "Building wheels for collected packages: sqlitedict, segtok\r\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\r\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\r\n",
      "Successfully built sqlitedict segtok\r\n",
      "Installing collected packages: sqlitedict, deprecated, segtok, bpemb, flair\r\n",
      "Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 segtok-1.5.7 sqlitedict-1.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i cant use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love u take with u all the time in urð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        ...                                                                clean_tweet\n",
       "0   1                        ...                           when a father is dysfunctional and is so self...\n",
       "1   2                        ...                           thanks for lyft credit i cant use cause they ...\n",
       "2   3                        ...                                                        bihday your majesty\n",
       "3   4                        ...                          model i love u take with u all the time in urð...\n",
       "4   5                        ...                                          factsguide society now motivation\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub('http\\S+\\s*', '', tweet)  # remove URLs\n",
    "    tweet = re.sub('RT|cc', '', tweet)  # remove RT and cc\n",
    "    tweet = re.sub('#', '', tweet)  # remove hashtags\n",
    "    tweet = re.sub('@\\S+', '', tweet)  # remove mentions\n",
    "    tweet = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), '', tweet)  # remove punctuations\n",
    "    tweet = re.sub('\\s+', ' ', tweet)  # remove extra whitespace\n",
    "    tweet = re.sub('\\d+',' ',tweet) #removes numbers\n",
    "    return tweet\n",
    "  \n",
    "\n",
    "train['clean_tweet'] = train['tweet'].apply(lambda x: clean_tweet(x))\n",
    "test['clean_tweet'] = test['tweet'].apply(lambda x: clean_tweet(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 04:51:28,315 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-forward-v0.1.pt not found in cache, downloading to /tmp/tmpih3ee8cp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034300/73034300 [00:09<00:00, 8067015.58B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 04:51:38,540 copying /tmp/tmpih3ee8cp to cache at /tmp/.flair/embeddings/lm-multi-forward-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 04:51:38,621 removing temp file /tmp/tmpih3ee8cp\n",
      "2019-06-29 04:51:46,207 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-backward-v0.1.pt not found in cache, downloading to /tmp/tmpm4c4x4da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034304/73034304 [00:08<00:00, 8156897.41B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 04:51:56,320 copying /tmp/tmpm4c4x4da to cache at /tmp/.flair/embeddings/lm-multi-backward-v0.1.pt\n",
      "2019-06-29 04:51:56,423 removing temp file /tmp/tmpm4c4x4da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 04:51:56,725 The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213450/213450 [00:00<00:00, 386057.62B/s]\n",
      "100%|██████████| 404400730/404400730 [00:32<00:00, 12604790.00B/s]\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/allennlp/commands/find_learning_rate.py:55: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')\n",
      "100%|██████████| 336/336 [00:00<00:00, 270029.92B/s]\n",
      "100%|██████████| 374434792/374434792 [00:24<00:00, 15496259.43B/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import ELMoEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "bert_embedding = BertEmbeddings('bert-base-cased')\n",
    "elmo_embedding = ELMoEmbeddings('original')\n",
    "\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "stacked_embeddings = StackedEmbeddings(\n",
    "    embeddings=[flair_forward_embedding, flair_backward_embedding, bert_embedding,elmo_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6421e-03,  4.3796e-07, -8.6378e-07,  ...,  1.9982e-01,\n",
      "        -3.7610e-01,  5.4207e-01])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-4.1463e-04,  3.7489e-07,  1.5540e-05,  ..., -3.0025e-01,\n",
      "         1.3170e+00,  1.0456e+00])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-9.5101e-04,  3.4755e-08, -2.8645e-06,  ..., -8.2120e-02,\n",
      "         4.0707e-01,  8.1440e-01])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('NLP is lit!')\n",
    "# embed words in sentence #\n",
    "stacked_embeddings.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token.embedding)\n",
    "# data type and size of embedding #\n",
    "    print(type(token.embedding))\n",
    "# storing size (length) #\n",
    "z = token.embedding.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvec = []\n",
    "for i in range(len(train)):\n",
    "    sent = torch.zeros(0,z)\n",
    "    sentence = Sentence(train['clean_tweet'][i])\n",
    "    stacked_embeddings.embed(sentence)\n",
    "    word = torch.zeros(0,z)\n",
    "    for token in sentence:\n",
    "        word = torch.cat((word,token.embedding.view(-1,z)),0)\n",
    "    sent = torch.cat((sent, word.mean(dim = 0).view(-1, z)),0)\n",
    "    trainvec.append(sent)\n",
    "train['embedding'] = trainvec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "stack_train_new = np.concatenate(train['embedding'], axis = 0)\n",
    "pickle_out = open(\"stack_train_03032019.pickle\",\"wb\")\n",
    "pickle.dump(stack_train_new, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvec = []\n",
    "append = testvec.append\n",
    "for i in range(len(test)):\n",
    "    sent = torch.zeros(0,z)\n",
    "    sentence = Sentence(test['clean_tweet'][i])\n",
    "    stacked_embeddings.embed(sentence)\n",
    "    word = torch.zeros(0,z)\n",
    "    for token in sentence:\n",
    "        word = torch.cat((word,token.embedding.view(-1,z)),0)\n",
    "    sent = torch.cat((sent, word.mean(dim = 0).view(-1, z)),0)\n",
    "    append(sent)\n",
    "test['embedding'] = testvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[[tensor(-0.0030), tensor(5.1520e-07), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white supremacists want everyone to see the n...</td>\n",
       "      <td>[[tensor(-0.0017), tensor(7.3739e-07), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your acne altwaystoheal heal...</td>\n",
       "      <td>[[tensor(-0.0040), tensor(1.6659e-06), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[[tensor(-0.0028), tensor(6.2595e-07), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd bihday to my amazing hilarious nephew eli...</td>\n",
       "      <td>[[tensor(-0.0005), tensor(7.1744e-07), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        ...                                                                  embedding\n",
       "0  31963                        ...                          [[tensor(-0.0030), tensor(5.1520e-07), tensor(...\n",
       "1  31964                        ...                          [[tensor(-0.0017), tensor(7.3739e-07), tensor(...\n",
       "2  31965                        ...                          [[tensor(-0.0040), tensor(1.6659e-06), tensor(...\n",
       "3  31966                        ...                          [[tensor(-0.0028), tensor(6.2595e-07), tensor(...\n",
       "4  31967                        ...                          [[tensor(-0.0005), tensor(7.1744e-07), tensor(...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test_new = np.concatenate(test['embedding'], axis = 0)\n",
    "pickle_out = open(\"stack_test_03032019.pickle\",\"wb\")\n",
    "pickle.dump(stack_test_new, pickle_out)\n",
    "pickle_out.close()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stack_train_new\n",
    "pickle_in = open(\"stack_train_03032019.pickle\", \"rb\")\n",
    "stack_train_new = pickle.load(pickle_in)\n",
    "\n",
    "#load stack_train_new\n",
    "pickle_in = open(\"stack_test_03032019.pickle\", \"rb\")\n",
    "stack_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train_new = np.where(np.isfinite(stack_train_new), stack_train_new, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_test_new = np.where(np.isfinite(stack_test_new), stack_test_new, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.metrics import accuracy_score\n",
    "X = stack_train_new\n",
    "y = train['label']\n",
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=3,random_state=1,shuffle=True) \n",
    "for train_index,test_index in kf.split(X,y):     \n",
    "    #print('\\n{} of kfold {}'.format(i,kf.n_splits))    \n",
    "    xtr,xvl = X[train_index],X[test_index]     \n",
    "    ytr,yvl = y[train_index],y[test_index]         \n",
    "    model1 = LogisticRegression(solver='lbfgs',max_iter=1500)     \n",
    "    model1.fit(xtr, ytr)     \n",
    "#     pred_test1 = model_svc.predict(xvl)    \n",
    "#     score = accuracy_score(yvl,pred_test1)     \n",
    "#     print('accuracy_score',score)    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.metrics import accuracy_score\n",
    "X = stack_train_new\n",
    "y = train['label']\n",
    "i=1 \n",
    "kf = StratifiedKFold(n_splits=3,random_state=1,shuffle=True) \n",
    "for train_index,test_index in kf.split(X,y):     \n",
    "    #print('\\n{} of kfold {}'.format(i,kf.n_splits))    \n",
    "    xtr,xvl = X[train_index],X[test_index]     \n",
    "    ytr,yvl = y[train_index],y[test_index]         \n",
    "    model_svc = LinearSVC(max_iter=500)     \n",
    "    model_svc.fit(xtr, ytr)     \n",
    "#     pred_test1 = model_svc.predict(xvl)    \n",
    "#     score = accuracy_score(yvl,pred_test1)     \n",
    "#     print('accuracy_score',score)    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model1.predict(stack_test_new)\n",
    "sub = pd.DataFrame({'id':test['id'], 'label':preds_test})\n",
    "\n",
    "# write predictions to a CSV file\n",
    "sub.to_csv(\"lreg3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model_svc.predict(stack_test_new)\n",
    "sub = pd.DataFrame({'id':test['id'], 'label':preds_test})\n",
    "\n",
    "# write predictions to a CSV file\n",
    "sub.to_csv(\"svc.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
